<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-us" lang="en-us">
<head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="generator" content="Hugo 0.76.5" />

  <title>Publications &middot; Bryan Eikema</title>

  <meta name="description" content="" />

  

<meta itemprop="name" content="Publications">
<meta itemprop="description" content="">
<meta itemprop="datePublished" content="2020-10-26T08:52:10+01:00" />
<meta itemprop="dateModified" content="2020-10-26T08:52:10+01:00" />
<meta itemprop="wordCount" content="0">



<meta itemprop="keywords" content="" />


<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Publications"/>
<meta name="twitter:description" content=""/>


<meta property="og:title" content="Publications" />
<meta property="og:description" content="" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://roxot.github.io/publications/" />
<meta property="article:published_time" content="2020-10-26T08:52:10+01:00" />
<meta property="article:modified_time" content="2020-10-26T08:52:10+01:00" />



<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@graph": [
    {
      "@type":"Person",
      "@id": "https://roxot.github.io/#author",
      "name": "Bryan Eikema",
      "image": {
        "@type":"ImageObject",
        
        "url": "https://roxot.github.io/images/bio-photo.jpg"
        
      },
      "description": "PhD Candidate"
    },
    {
      "@type": "WebSite",
      "@id": "https://roxot.github.io/#website",
      "url": "https://roxot.github.io/",
      "name": "Bryan Eikema",
      "description": "PhD Candidate",
      "publisher": {
        "@id": "https://roxot.github.io/#author"
      },
      "inLanguage": "en-us"
    },
    {
      "@type": "WebPage",
      "@id": "https://roxot.github.io/publications/#webpage",
      "url": "https://roxot.github.io/publications/",
      "name": "Publications",
      "isPartOf": {
        "@id": "https://roxot.github.io/#website"
      },
      "about": {
         "@id": "https://roxot.github.io/#author"
      },
      "datePublished": "2020-10-26T08:52:10+01:00",
      "dateModified": "2020-10-26T08:52:10+01:00",
      "description": "",
      "inLanguage": "en-us",
      "potentialAction": [
        {
          "@type": "ReadAction",
          "target": [
            "https://roxot.github.io/publications/"
          ]
        }
      ]
    },
    {
      "@type": "Article",
      "isPartOf": {
        "@id": "https://roxot.github.io/publications/#webpage"
      },
      "mainEntityOfPage": {
        "@id": "https://roxot.github.io/publications/#webpage"
      },
      "headline": "Publications",
      "datePublished": "2020-10-26T08:52:10+01:00",
      "dateModified": "2020-10-26T08:52:10+01:00",
      "publisher": {
        "@id": "https://roxot.github.io/#author"
      },
      "keywords": [
      ],
      "articleSection": [
      ],
      "inLanguage": "en-us",
      "author": {
        "@type": "Person",
        "name":  null 
      },
      "potentialAction": [
        {
          "@type": "CommentAction",
          "name": "Comment",
          "target": [
            "https://roxot.github.io/publications/#comments"
          ]
        }
      ]
    }
  ]
}
</script>



  <link type="text/css"
        rel="stylesheet"
        href="/css/print.css"
        media="print">

  <link type="text/css"
        rel="stylesheet"
        href="/css/poole.css">

  <link type="text/css"
        rel="stylesheet"
        href="/css/hyde.css">

  
<style type="text/css">
    .sidebar {
        background-color: #1e88e5;
    }

    .read-more-link a {
        border-color: #1e88e5;
    }

    .pagination li a {
        color: #1e88e5;
        border: 1px solid #1e88e5;
    }

    .pagination li.active a {
        background-color: #1e88e5;
    }

    .pagination li a:hover {
        background-color: #1e88e5;
        opacity: 0.75;
    }

    footer a,
    .content a,
    .related-posts li a:hover {
        color: #1e88e5
    }

    .pub-btn {
        background-color: #1e88e5;
        color: white;
        text-align: center;
        padding: 4px 6px;
        font-size: 15px;
        border-style: none;
        border-radius: 3px;
        opacity: 0.7;
        transition: 0.3s;
        cursor: pointer;
    }

    .download-btn a,
    .copy-btn a {
        background-color: #1e88e5;
        color: white;
        text-align: center;
        padding: 4px 6px;
        font-size: 15px;
        border-style: none;
        border-radius: 3px;
        opacity: 0.7;
        transition: 0.3s;
        cursor: pointer;
        text-decoration: none;
    }

    .download-btn a:hover {
    .copy-btn a:hover,
        text-decoration: none;
        opacity: 1;
    }

    .pub-btn:hover {
        opacity: 1;
    }

</style>



  <link type="text/css" rel="stylesheet" href="/css/general.css"><link type="text/css" rel="stylesheet" href="/css/publications.css">

  <link rel="stylesheet"
        href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700&display=swap">

  <link rel="stylesheet"
        href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css"
        integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk="
        crossorigin="anonymous" />

    
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
    <link rel="manifest" href="/site.webmanifest">
    <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
    <meta name="msapplication-TileColor" content="#da532c">
    <meta name="theme-color" content="#ffffff">

    
    
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-9GLPM3R7S3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-9GLPM3R7S3');
    </script>

  
  </head>
<body>
  <aside class="sidebar">
  <div class="container">
    <div class="sidebar-about">
      
        
        <div class="author-image">
          <img src="/images/bio-photo.jpg" class="img-circle img-headshot center" alt="Profile Picture">
        </div>
        
      

      <h1 class="custom-title">Bryan Eikema</h1>

      
      
      <p>PhD Candidate</br>University of Amsterdam</p>
      

    </div>

    <nav>
      <ul class="sidebar-nav">
        <li>
          <a href="https://roxot.github.io/">About</a>
        </li>
        <li>
          <a href="/publications/">Publications</a>
        </li>
      </ul>
    
    
    
    
    </nav>

    <section class="social-icons">
      
      <a href="mailto:bryan.eikema@gmail.com" rel="me" title="Email" target="_blank" class="custom">
        <i class="fas fa-envelope" aria-hidden="true"></i>
      </a>
      
      <a href="https://github.com/roxot" rel="me" title="GitHub" target="_blank" class="custom">
        <i class="fab fa-github" aria-hidden="true"></i>
      </a>
      
      <a href="https://twitter.com/bryaneikema" rel="me" title="Twitter" target="_blank" class="custom">
        <i class="fab fa-twitter" aria-hidden="true"></i>
      </a>
      
      <a href="https://www.linkedin.com/in/bryan-eikema-b5a3b482/" rel="me" title="LinkedIn" target="_blank" class="custom">
        <i class="fab fa-linkedin" aria-hidden="true"></i>
      </a>
      
    </section>
  </div>
</aside>


  <main class="content container">
  <h1 class="title">Publications</h1>




    <div style="margin-bottom: 0.5cm;">

    <b>Sampling from Discrete Energy-Based Models with Quality/Efficiency Trade-offs</b><br/>
    Bryan Eikema, Germ√°n Kruszewski, Hady Elsahar, Marc Dymetman in <em>arXiv</em>, 2021
    
    <br/>

    <div style="margin-top: 3px; margin-bottom: 10px;">
    
    <button type="button" class="pub-btn open-modal open-abstract">abstract</button>
    
    <form action="//arxiv.org/pdf/2112.05702.pdf" target="blank" style="display: inline;">
            <button type="submit" class="pub-btn">pdf</button>
    </form>
    
    
    <button type="button" class="pub-btn open-modal open-cite">cite</button>
    <br />
    
    </div>


    
    <div class="modal">
        <div class="modal-content">
            <div class="modal-header">
                <span class="modal-title"><b>Sampling from Discrete Energy-Based Models with Quality/Efficiency Trade-offs</b></span>
                <span class="close-modal"><b>&times;</b></span>
            </div>
            <div class="modal-body">
                <p class="abstract-content" lang="en">Energy-Based Models (EBMs) allow for extremely flexible specifications of probability distributions. However, they do not provide a mechanism for obtaining exact samples from these distributions. Monte Carlo techniques can aid us in obtaining samples if some proposal distribution that we can easily sample from is available. For instance, rejection sampling can provide exact samples but is often difficult or impossible to apply due to the need to find a proposal distribution that upper-bounds the target distribution everywhere. Approximate Markov chain Monte Carlo sampling techniques like Metropolis-Hastings are usually easier to design, exploiting a local proposal distribution that performs local edits on an evolving sample. However, these techniques can be inefficient due to the local nature of the proposal distribution and do not provide an estimate of the quality of their samples. In this work, we propose a new approximate sampling technique, Quasi Rejection Sampling (QRS), that allows for a trade-off between sampling efficiency and sampling quality, while providing explicit convergence bounds and diagnostics. QRS capitalizes on the availability of high-quality global proposal distributions obtained from deep learning models. We demonstrate the effectiveness of QRS sampling for discrete EBMs over text for the tasks of controlled text generation with distributional constraints and paraphrase generation. We show that we can sample from such EBMs with arbitrary precision at the cost of sampling efficiency.
</p>
            </div>
        </div>
    </div>
    

    
    <div class="modal">
        <div class="modal-content">
            <div class="modal-header">
            <b>Cite</b><b class="close-modal">&times;</b>
            </div>
            <div class="modal-body">
                <pre class="bibtex-content">@article{eikema-et-al-2021-sampling,
  author    = {Bryan Eikema and
               Germ{\&#39;{a}}n Kruszewski and
               Hady Elsahar and
               Marc Dymetman},
  title     = {Sampling from Discrete Energy-Based Models with Quality/Efficiency
               Trade-offs},
  journal   = {CoRR},
  volume    = {abs/2112.05702},
  year      = {2021},
  url       = {https://arxiv.org/abs/2112.05702},
  eprinttype = {arXiv},
  eprint    = {2112.05702}
}
</pre>
            </div>
            <div class="modal-footer">
                <span class="download-btn">
                    <a class="copy-btn"><i class="fa fa-copy"></i> Copy</a>
                </span>
                <span class="download-btn">
                    <a href="/files/bibtex/sampling-with-diagnostics.bib" download><i class="fa fa-download"></i> Download</a>
                </span>
                <i class="status-text"></i>
            </div>
        </div>
    </div>
    

</div>


    <div style="margin-bottom: 0.5cm;">

    <b>Sampling-Based Minimum Bayes Risk Decoding for Neural Machine Translation</b><br/>
    Bryan Eikema and Wilker Aziz in <em>arXiv</em>, 2021
    
    <br/>

    <div style="margin-top: 3px; margin-bottom: 10px;">
    
    <button type="button" class="pub-btn open-modal open-abstract">abstract</button>
    
    <form action="//arxiv.org/pdf/2108.04718.pdf" target="blank" style="display: inline;">
            <button type="submit" class="pub-btn">pdf</button>
    </form>
    
    
    <button type="button" class="pub-btn open-modal open-cite">cite</button>
    <br />
    
    </div>


    
    <div class="modal">
        <div class="modal-content">
            <div class="modal-header">
                <span class="modal-title"><b>Sampling-Based Minimum Bayes Risk Decoding for Neural Machine Translation</b></span>
                <span class="close-modal"><b>&times;</b></span>
            </div>
            <div class="modal-body">
                <p class="abstract-content" lang="en">In neural machine translation (NMT), we search for the mode of the model distribution to form predictions. The mode as well as other high probability translations found by beam search have been shown to often be inadequate in a number of ways. This prevents practitioners from improving translation quality through better search, as these idiosyncratic translations end up being selected by the decoding algorithm, a problem known as the beam search curse. Recently, a sampling-based approximation to minimum Bayes risk (MBR) decoding has been proposed as an alternative decision rule for NMT that would likely not suffer from the same problems. We analyse this approximation and establish that it has no equivalent to the beam search curse, i.e. better search always leads to better translations. We also design different approximations aimed at decoupling the cost of exploration from the cost of robust estimation of expected utility. This allows for exploration of much larger hypothesis spaces, which we show to be beneficial. We also show that it can be beneficial to make use of strategies like beam search and nucleus sampling to construct hypothesis spaces efficiently. We show on three language pairs (English into and from German, Romanian, and Nepali) that MBR can improve upon beam search with moderate computation.
</p>
            </div>
        </div>
    </div>
    

    
    <div class="modal">
        <div class="modal-content">
            <div class="modal-header">
            <b>Cite</b><b class="close-modal">&times;</b>
            </div>
            <div class="modal-body">
                <pre class="bibtex-content">@article{eikema-aziz-2021-sampling,
  author    = {Bryan Eikema and
               Wilker Aziz},
  title     = {Sampling-Based Minimum Bayes Risk Decoding for Neural Machine Translation},
  journal   = {CoRR},
  volume    = {abs/2108.04718},
  year      = {2021},
  url       = {https://arxiv.org/abs/2108.04718},
  eprinttype = {arXiv},
  eprint    = {2108.04718}
}
</pre>
            </div>
            <div class="modal-footer">
                <span class="download-btn">
                    <a class="copy-btn"><i class="fa fa-copy"></i> Copy</a>
                </span>
                <span class="download-btn">
                    <a href="/files/bibtex/sampling-based-mbr.bib" download><i class="fa fa-download"></i> Download</a>
                </span>
                <i class="status-text"></i>
            </div>
        </div>
    </div>
    

</div>


    <div style="margin-bottom: 0.5cm;">

    <b>Is MAP Decoding All You Need? The Inadequacy of the Mode in Neural Machine Translation</b><br/>
    Bryan Eikema and Wilker Aziz in <em>Proceedings of the 28th International Conference on Computational Linguistics (COLING)</em>, 2020
    
        <em style="color: #f44336;">Best Paper Award</em>
    
    <br/>

    <div style="margin-top: 3px; margin-bottom: 10px;">
    
    <button type="button" class="pub-btn open-modal open-abstract">abstract</button>
    
    <form action="//aclweb.org/anthology/2020.coling-main.398.pdf" target="blank" style="display: inline;">
            <button type="submit" class="pub-btn">pdf</button>
    </form>
    
    
    <button type="button" class="pub-btn open-modal open-cite">cite</button>
    <br />
    
    </div>


    
    <div class="modal">
        <div class="modal-content">
            <div class="modal-header">
                <span class="modal-title"><b>Is MAP Decoding All You Need? The Inadequacy of the Mode in Neural Machine Translation</b></span>
                <span class="close-modal"><b>&times;</b></span>
            </div>
            <div class="modal-body">
                <p class="abstract-content" lang="en">Recent studies have revealed a number of pathologies of neural machine translation (NMT) systems. Hypotheses explaining these mostly suggest there is something fundamentally wrong with NMT as a model or its training algorithm, maximum likelihood estimation (MLE). Most of this evidence was gathered using maximum a posteriori (MAP) decoding, a decision rule aimed at identifying the highest-scoring translation, i.e. the mode. We argue that the evidence corroborates the inadequacy of MAP decoding more than casts doubt on the model and its training algorithm. In this work, we show that translation distributions do reproduce various statistics of the data well, but that beam search strays from such statistics. We show that some of the known pathologies and biases of NMT are due to MAP decoding and not to NMT&#39;s statistical assumptions nor MLE. In particular, we show that the most likely translations under the model accumulate so little probability mass that the mode can be considered essentially arbitrary. We therefore advocate for the use of decision rules that take into account the translation distribution holistically. We show that an approximation to minimum Bayes risk decoding gives competitive results confirming that NMT models do capture important aspects of translation well in expectation.
</p>
            </div>
        </div>
    </div>
    

    
    <div class="modal">
        <div class="modal-content">
            <div class="modal-header">
            <b>Cite</b><b class="close-modal">&times;</b>
            </div>
            <div class="modal-body">
                <pre class="bibtex-content">@inproceedings{eikema-aziz-2020-is,
    title = &#34;Is MAP Decoding All You Need? The Inadequacy of the Mode in Neural Machine Translation&#34;,
    author = &#34;Eikema, Bryan  and
      Aziz, Wilker&#34;,
    booktitle = &#34;Proceedings of the 28th International Conference on Computational Linguistics&#34;,
    month = dec,
    year = &#34;2020&#34;,
    address = &#34;Barcelona, Spain&#34;,
    publisher = &#34;Association for Computational Linguistics&#34;,
}
</pre>
            </div>
            <div class="modal-footer">
                <span class="download-btn">
                    <a class="copy-btn"><i class="fa fa-copy"></i> Copy</a>
                </span>
                <span class="download-btn">
                    <a href="/files/bibtex/inadequacy-mode.bib" download><i class="fa fa-download"></i> Download</a>
                </span>
                <i class="status-text"></i>
            </div>
        </div>
    </div>
    

</div>


    <div style="margin-bottom: 0.5cm;">

    <b>Auto-Encoding Variational Neural Machine Translation</b><br/>
    Bryan Eikema and Wilker Aziz in <em>Proceedings of the 4th Workshop on Representation Learning for NLP (RepL4NLP)</em>, 2019
    
    <br/>

    <div style="margin-top: 3px; margin-bottom: 10px;">
    
    <button type="button" class="pub-btn open-modal open-abstract">abstract</button>
    
    <form action="//aclweb.org/anthology/W19-4315.pdf" target="blank" style="display: inline;">
            <button type="submit" class="pub-btn">pdf</button>
    </form>
    
    <form action="//github.com/Roxot/AEVNMT" target="blank" style="display: inline;">
            <button class="pub-btn" type="submit">code</button>
    </form>
    
    
    <button type="button" class="pub-btn open-modal open-cite">cite</button>
    <br />
    
    </div>


    
    <div class="modal">
        <div class="modal-content">
            <div class="modal-header">
                <span class="modal-title"><b>Auto-Encoding Variational Neural Machine Translation</b></span>
                <span class="close-modal"><b>&times;</b></span>
            </div>
            <div class="modal-body">
                <p class="abstract-content" lang="en">We present a deep generative model of bilingual sentence pairs for machine translation. The model generates source and target sentences jointly from a shared latent representation and is parameterised by neural networks. We perform efficient training using amortised variational inference and reparameterised gradients. Additionally, we discuss the statistical implications of joint modelling and propose an efficient approximation to maximum a posteriori decoding for fast test-time predictions. We demonstrate the effectiveness of our model in three machine translation scenarios: in-domain training, mixed-domain training, and learning from a mix of gold-standard and synthetic data. Our experiments show consistently that our joint formulation outperforms conditional modelling (i.e. standard neural machine translation) in all such scenarios.
</p>
            </div>
        </div>
    </div>
    

    
    <div class="modal">
        <div class="modal-content">
            <div class="modal-header">
            <b>Cite</b><b class="close-modal">&times;</b>
            </div>
            <div class="modal-body">
                <pre class="bibtex-content">@inproceedings{eikema-aziz-2019-auto,
    title = &#34;Auto-Encoding Variational Neural Machine Translation&#34;,
    author = &#34;Eikema, Bryan  and
      Aziz, Wilker&#34;,
    booktitle = &#34;Proceedings of the 4th Workshop on Representation Learning for NLP (RepL4NLP-2019)&#34;,
    month = aug,
    year = &#34;2019&#34;,
    address = &#34;Florence, Italy&#34;,
    publisher = &#34;Association for Computational Linguistics&#34;,
    url = &#34;https://www.aclweb.org/anthology/W19-4315&#34;,
    doi = &#34;10.18653/v1/W19-4315&#34;,
    pages = &#34;124--141&#34;,
    abstract = &#34;We present a deep generative model of bilingual sentence pairs for machine translation. The model generates source and target sentences jointly from a shared latent representation and is parameterised by neural networks. We perform efficient training using amortised variational inference and reparameterised gradients. Additionally, we discuss the statistical implications of joint modelling and propose an efficient approximation to maximum a posteriori decoding for fast test-time predictions. We demonstrate the effectiveness of our model in three machine translation scenarios: in-domain training, mixed-domain training, and learning from a mix of gold-standard and synthetic data. Our experiments show consistently that our joint formulation outperforms conditional modelling (i.e. standard neural machine translation) in all such scenarios.&#34;,
}
</pre>
            </div>
            <div class="modal-footer">
                <span class="download-btn">
                    <a class="copy-btn"><i class="fa fa-copy"></i> Copy</a>
                </span>
                <span class="download-btn">
                    <a href="/files/bibtex/aevnmt.bib" download><i class="fa fa-download"></i> Download</a>
                </span>
                <i class="status-text"></i>
            </div>
        </div>
    </div>
    

</div>


    <div style="margin-bottom: 0.5cm;">

    <b>Master&#39;s Thesis: Auto-Encoding Variational Neural Machine Translation</b><br/>
    Bryan Eikema in <em>UvA Scripties Online</em>, 2018
    
    <br/>

    <div style="margin-top: 3px; margin-bottom: 10px;">
    
    <button type="button" class="pub-btn open-modal open-abstract">abstract</button>
    
    <form action="//esc.fnwi.uva.nl/thesis/centraal/files/f344704273.pdf" target="blank" style="display: inline;">
            <button type="submit" class="pub-btn">pdf</button>
    </form>
    
    
    <button type="button" class="pub-btn open-modal open-cite">cite</button>
    <br />
    
    </div>


    
    <div class="modal">
        <div class="modal-content">
            <div class="modal-header">
                <span class="modal-title"><b>Master&#39;s Thesis: Auto-Encoding Variational Neural Machine Translation</b></span>
                <span class="close-modal"><b>&times;</b></span>
            </div>
            <div class="modal-body">
                <p class="abstract-content" lang="en">Translation data is often a byproduct of mixing different sources of data. This could be intentional such as by mixing data of different domains or including back-translated monolingual data, but often also is the result of how the bilingual dataset was constructed: a combination of different documents independently translated in different translation directions, by different translators, agencies, etc. Most neural machine translation models do not explicitly account for such variation in their probabilistic model. We attempt to model this by proposing a deep generative model that generates source and target sentences jointly from a shared sentence-level latent representation. The latent representation is designed to capture variations in the data distribution and allows the model to adjust its language and translation model accordingly. We show that such a model leads to superior performance over a strong conditional neural machine translation baseline in three settings: in-domain training where the training and test data are of the same domain, mixed-domain training where we train on a mix of domains and test on each domain separately, and in-domain training where we also include synthetic (noisy) back-translated data. We furthermore extend the model to be used in a semi-supervised setting in order to incorporate target monolingual data during training. Doing this we derive the commonly employed backtranslation heuristic in the form of a variational approximation to the posterior over the missing source sentence. This allows for training the back-translation network jointly with the rest of the model on a shared objective designed for source-to-target translation with minimal need of pre-processing. We find that the performance of this approach is not on par with the back-translation heuristic, but does lead to improvement over a model trained on bilingual data alone.
</p>
            </div>
        </div>
    </div>
    

    
    <div class="modal">
        <div class="modal-content">
            <div class="modal-header">
            <b>Cite</b><b class="close-modal">&times;</b>
            </div>
            <div class="modal-body">
                <pre class="bibtex-content">@mastersthesis{eikema-msc-thesis-2018,
    author = &#34;Bryan Eikema&#34;,
    title = &#34;Auto-Encoding Variational Neural Machine Translation&#34;,
    school = &#34;University of Amsterdam&#34;,
    year = 2018,
    address = &#34;Amsterdam, The Netherlands&#34;,
    month = sep,
    publisher = &#34;UvA Scripties Online&#34;,
}
</pre>
            </div>
            <div class="modal-footer">
                <span class="download-btn">
                    <a class="copy-btn"><i class="fa fa-copy"></i> Copy</a>
                </span>
                <span class="download-btn">
                    <a href="/files/bibtex/msc-thesis.bib" download><i class="fa fa-download"></i> Download</a>
                </span>
                <i class="status-text"></i>
            </div>
        </div>
    </div>
    

</div>



<script>
    
    function copyToClipboard(value) {
        var aux = document.createElement("input");
        aux.setAttribute("value", value);
        document.body.appendChild(aux);
        aux.select();
        try {
            var success = document.execCommand("copy");
        } catch (err) {
            var success = false;
        }
        document.body.removeChild(aux);
        return success;
    }

    
    function runAnimation(modal) {
        modalContent = modal.querySelector(".modal-content");
        modalContent.classList.add("animate-modal");
    }

    
    function resetAnimation(modal) {
        modalContent = modal.querySelector(".modal-content");
        modalContent.classList.remove("animate-modal");
    }

    
    function openModal(modal) {
        modal.style.display = "block";
        $("body").addClass("modal-open");
        runAnimation(modal);
    }

    
    function closeModal(modal) {
        modal.style.display = "none";
        $("body").removeClass("modal-open");
        statusText = modal.querySelector(".status-text");
        if (statusText) {
            statusText.innerHTML = "";
        }
        resetAnimation(modal);
    }


    const buttons = document.querySelectorAll(".open-modal");
    const modals = document.querySelectorAll(".modal");
    modals.forEach(function(modal, index) {

        button = buttons.item(index);

        
        button.onclick = () => {
            openModal(modal);
        };

        
        modal.querySelector(".close-modal").onclick = () => {
            closeModal(modal);
        };

        
        modal.onclick = (event) => {
            if (event.target == modal) closeModal(modal);
        };

        copyButton = modal.querySelector(".copy-btn");
        if (copyButton) {
            copyButton.onclick = () => {
                statusText = modal.querySelector(".status-text");
                bibtex = modal.querySelector(".bibtex-content");
                success = copyToClipboard(bibtex.innerHTML);
                if (success) {
                    statusText.innerHTML = "Copied to clipboard!";
                } else {
                    statusText.innerHTML = "Failed to copy.";
                }
            };
        }
    });

</script>

  </main>

  <footer>
  <div>
    <p>
      &copy; Bryan Eikema 2022

      

      
    </p>
  </div>
</footer>


  <script src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/js/all.min.js"
          integrity="sha256-MAgcygDRahs+F/Nk5Vz387whB4kSK9NXlDN3w58LLq0="
          crossorigin="anonymous"></script>


  <script src="/js/jquery.min.js"></script>
  <script src="/js/soho.js"></script>

  

  
</body>
</html>
